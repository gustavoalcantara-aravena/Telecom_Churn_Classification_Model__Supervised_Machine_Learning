# ğŸ“‰ Telecom_Churn_Classification_Model__Supervised_Machine_Learning

This project focuses on predicting customer churn in a telecommunications company using supervised machine learning. Several classic classification models were implemented and evaluated under different class imbalance scenarios, including the application of the SMOTE oversampling technique.

The work was developed as part of the **Data Science, Machine Learning, Artificial Intelligence, and Deep Learning Diploma** at the Pontificia Universidad CatÃ³lica de ValparaÃ­so (PUCV), Chile, in 2025.

---

## ğŸ§ª Techniques Used

### ğŸ” Exploratory Data Analysis (EDA)
- Statistical summaries (`mean`, `std`, `min`, `max`, etc.)
- Visualizations:
  - Histograms and boxplots for numerical variables
  - Bar plots for categorical distributions
- Contingency tables to analyze relationships (e.g., international plan vs. churn)
- Outlier detection using the **interquartile range (IQR)** method

### âš™ï¸ Data Preprocessing
- Removal of non-informative variables (`phone number`, `customer ID`)
- Label encoding for binary variables (e.g., `International Plan`)
- One-hot encoding for categorical variables (e.g., `State`)
- Feature scaling using `StandardScaler`

### ğŸ›  Feature Engineering
- Derived feature: `customer_service_cat` (based on number of service calls)
  - Groups: 0â€“1 calls, 2â€“3 calls, 4 or more
- Detection of key churn predictors based on initial insights

### ğŸ§  Classification Models
- **Random Forest Classifier**
- **Support Vector Machine (SVM)** with RBF kernel

### âš–ï¸ Class Imbalance Handling
- **SMOTE** (Synthetic Minority Over-sampling Technique) applied in two scenarios:
  1. SMOTE applied to both models
  2. Hybrid: RF without SMOTE, SVM with SMOTE

### ğŸ“ Model Evaluation
- Metrics:
  - Accuracy
  - Precision, Recall, F1-Score (focused on churn class)
  - Area Under the Curve (AUC-ROC)
  - Precision-Recall Curve
- Confusion Matrices
- Visual comparison of performance across all models

---

## ğŸ“Š Key Results

| Model                                | Accuracy | Precision (Churn) | Recall (Churn) | F1-Score (Churn) | SMOTE |
|-------------------------------------|----------|-------------------|----------------|------------------|--------|
| Random Forest (no SMOTE)            | 95%      | 0.92              | 0.70           | 0.80             | âŒ     |
| SVM (no SMOTE)                      | 92%      | 0.88              | 0.50           | 0.63             | âŒ     |
| Random Forest (SMOTE)               | 92%      | 0.70              | 0.74           | 0.72             | âœ…     |
| SVM (SMOTE)                         | 87%      | 0.54              | 0.66           | 0.59             | âœ…     |
| RF (no SMOTE) + SVM (with SMOTE)    | 95% / 87%| 0.92 / 0.54       | 0.70 / 0.66    | 0.80 / 0.59      | Mixed  |

> âœ… The best overall performance was achieved using **Random Forest without SMOTE**, reaching **95% accuracy** and an **F1-Score of 0.80** for the minority class (churn).

---

## ğŸ“‚ Repository Structure
modelo-clasificacion-churn-telecom/
â”œâ”€â”€ README.md
â”œâ”€â”€ Gustavo_AlcÃ¡ntara_Modelo_de_ClasificaciÃ³n.ipynb # Full model in Jupyter Notebook
â”œâ”€â”€ Gustavo_AlcÃ¡ntara_Modelo_de_ClasificaciÃ³n_Diplomado_IA_PUCV_Mayo_2025.pdf # Full report
â”œâ”€â”€ data/
â”‚ â””â”€â”€ churn-analysis.csv # Dataset (if shareable)
â””â”€â”€ images/
â””â”€â”€ ... # Visualizations (optional)


---

## ğŸ§° Tools & Libraries

- Python 3.10+
- Jupyter Notebook
- `pandas`, `numpy`
- `scikit-learn`
- `imbalanced-learn`
- `matplotlib`, `seaborn`



## ğŸ“ˆ Dataset
- The dataset consists of 3,333 customer records and 20 features, including:

- Call duration and charges (day, evening, night, international)

- Number of service calls

- Subscription to international plan and voicemail

- Target variable: churn (1 = customer left, 0 = customer stayed)

- Class imbalance: 14.5% churn rate

## ğŸ“Œ Business Recommendations
Prioritize Random Forest without SMOTE for deployment due to its balance of performance and simplicity.

- Focus retention efforts on:

- Customers with international plans

- Customers with 4+ service calls

- Customers without voicemail services



# ğŸ“‰ Modelo de ClasificaciÃ³n de Fuga de Clientes (Churn) - Telecomunicaciones

Este proyecto aborda el problema de **predicciÃ³n de la fuga de clientes (churn)** en una empresa de telecomunicaciones, utilizando tÃ©cnicas de **aprendizaje automÃ¡tico supervisado**. Se implementaron modelos clÃ¡sicos de clasificaciÃ³n bajo distintos escenarios de desbalance de clases, incluyendo la tÃ©cnica de sobremuestreo **SMOTE**.

Este trabajo fue desarrollado en el contexto del **Diplomado en Ciencia de Datos, Machine Learning, Inteligencia Artificial y Deep Learning** de la **Pontificia Universidad CatÃ³lica de ValparaÃ­so (PUCV)**, Chile, en el aÃ±o 2025.

---

## ğŸ§ª TÃ©cnicas utilizadas

### ğŸ” AnÃ¡lisis Exploratorio de Datos (EDA)
- EstadÃ­sticas descriptivas (`media`, `desv. estÃ¡ndar`, `mÃ­nimo`, `mÃ¡ximo`, etc.)
- Visualizaciones:
  - Histogramas y boxplots para variables numÃ©ricas
  - GrÃ¡ficos de barras para variables categÃ³ricas
- Tablas de contingencia para explorar relaciones entre variables
- DetecciÃ³n de valores atÃ­picos utilizando el **rango intercuartÃ­lico (IQR)**

### âš™ï¸ Preprocesamiento de datos
- EliminaciÃ³n de variables no informativas (`nÃºmero de telÃ©fono`, `ID cliente`)
- CodificaciÃ³n de variables:
  - `Label Encoding` para binarias
  - `One-Hot Encoding` para categÃ³ricas con mÃºltiples valores
- NormalizaciÃ³n de variables numÃ©ricas con `StandardScaler`

### ğŸ›  IngenierÃ­a de caracterÃ­sticas
- Variable derivada: `customer_service_cat` (categoriza nÃºmero de llamadas)
  - Grupos: 0â€“1 llamadas, 2â€“3 llamadas, 4 o mÃ¡s
- SelecciÃ³n de atributos con mayor poder predictivo

### ğŸ§  Modelos de ClasificaciÃ³n
- **Random Forest Classifier**
- **Support Vector Machine (SVM)** con kernel RBF

### âš–ï¸ Manejo de desbalance de clases
- AplicaciÃ³n de **SMOTE** en dos escenarios:
  1. SMOTE aplicado a ambos modelos
  2. Enfoque hÃ­brido: Random Forest sin SMOTE, SVM con SMOTE

### ğŸ“ EvaluaciÃ³n de modelos
- MÃ©tricas:
  - Accuracy
  - PrecisiÃ³n, Recall, F1-Score (especialmente para clase *churn*)
  - Curva ROC (AUC)
  - Curva Precision-Recall
- Matrices de confusiÃ³n
- ComparaciÃ³n visual entre modelos

---

## ğŸ“Š Resultados clave

| Modelo                              | Accuracy | PrecisiÃ³n (Churn) | Recall (Churn) | F1-Score (Churn) | SMOTE |
|------------------------------------|----------|-------------------|----------------|------------------|--------|
| Random Forest (sin SMOTE)          | 95%      | 0.92              | 0.70           | 0.80             | âŒ     |
| SVM (sin SMOTE)                    | 92%      | 0.88              | 0.50           | 0.63             | âŒ     |
| Random Forest (con SMOTE)          | 92%      | 0.70              | 0.74           | 0.72             | âœ…     |
| SVM (con SMOTE)                    | 87%      | 0.54              | 0.66           | 0.59             | âœ…     |
| RF (sin SMOTE) + SVM (con SMOTE)   | 95% / 87%| 0.92 / 0.54       | 0.70 / 0.66    | 0.80 / 0.59      | Mixto  |

> âœ… El mejor desempeÃ±o general fue obtenido con **Random Forest sin SMOTE**, alcanzando un **95% de accuracy** y un **F1-Score de 0.80** para la clase minoritaria (*churn*).

---

## ğŸ“‚ Estructura del repositorio


modelo-clasificacion-churn-telecom/
â”œâ”€â”€ README.md
â”œâ”€â”€ Gustavo_AlcÃ¡ntara_Modelo_de_ClasificaciÃ³n.ipynb # Notebook completo
â”œâ”€â”€ Gustavo_AlcÃ¡ntara_Modelo_de_ClasificaciÃ³n_Diplomado_IA_PUCV_Mayo_2025.pdf
â”œâ”€â”€ data/
  â””â”€â”€ churn-analysis.csv

---

## ğŸ§° Herramientas y librerÃ­as

- Python 3.10+
- Jupyter Notebook
- `pandas`, `numpy`
- `scikit-learn`
- `imbalanced-learn`
- `matplotlib`, `seaborn`

---

## ğŸ“ˆ Dataset
- El conjunto de datos contiene 3.333 registros de clientes y 20 atributos, incluyendo:

- DuraciÃ³n y cargos de llamadas (dÃ­a, tarde, noche, internacional)

- NÃºmero de llamadas al servicio al cliente

- Planes contratados (internacional, buzÃ³n de voz)

- Variable objetivo: churn (1 = abandono, 0 = permanencia)

- DistribuciÃ³n: 14.5 % de churn (desbalance significativo)

---

## ğŸ“Œ Recomendaciones para el negocio
- Adoptar el modelo de Random Forest sin SMOTE como herramienta base de predicciÃ³n.

- Focalizar estrategias de retenciÃ³n en:

- Clientes con planes internacionales

- Clientes que realizaron 4 o mÃ¡s llamadas al servicio

- Clientes sin buzÃ³n de voz

---

## ğŸ§‘ Autor
Gustavo AlcÃ¡ntara Aravena

ğŸ“˜ Diplomado en Ciencia de Datos, Machine Learning, IA, Deep Learning
Pontificia Universidad CatÃ³lica de ValparaÃ­so (PUCV)
ğŸ“ ValparaÃ­so, Chile | 2025
